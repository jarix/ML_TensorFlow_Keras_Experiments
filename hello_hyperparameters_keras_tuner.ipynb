{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello Hyperparameter optimization with Keras tuner\n",
    "\n",
    "For more details on the bank customer churn binary classifier example, see ```hello_bank_customer_churn_binary_classifier.ipynb ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version:  3.12.7 (tags/v3.12.7:0b05ead, Oct  1 2024, 03:06:41) [MSC v.1941 64 bit (AMD64)]\n",
      "Numpy Version:  2.0.2\n",
      "Pandas Version:  2.2.3\n"
     ]
    }
   ],
   "source": [
    "# Prerequisites\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "print(\"Python Version: \", sys.version)\n",
    "print(\"Numpy Version: \", np.__version__)\n",
    "print(\"Pandas Version: \", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "RowNumber",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CustomerId",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Surname",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "CreditScore",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Geography",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Tenure",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Balance",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "NumOfProducts",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "HasCrCard",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "IsActiveMember",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EstimatedSalary",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Exited",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "dc51d4d2-e7d6-4f47-ae17-58629af55801",
       "rows": [
        [
         "0",
         "1",
         "15634602",
         "Hargrave",
         "619",
         "France",
         "Female",
         "42",
         "2",
         "0.0",
         "1",
         "1",
         "1",
         "101348.88",
         "1"
        ],
        [
         "1",
         "2",
         "15647311",
         "Hill",
         "608",
         "Spain",
         "Female",
         "41",
         "1",
         "83807.86",
         "1",
         "0",
         "1",
         "112542.58",
         "0"
        ],
        [
         "2",
         "3",
         "15619304",
         "Onio",
         "502",
         "France",
         "Female",
         "42",
         "8",
         "159660.8",
         "3",
         "1",
         "0",
         "113931.57",
         "1"
        ],
        [
         "3",
         "4",
         "15701354",
         "Boni",
         "699",
         "France",
         "Female",
         "39",
         "1",
         "0.0",
         "2",
         "0",
         "0",
         "93826.63",
         "0"
        ],
        [
         "4",
         "5",
         "15737888",
         "Mitchell",
         "850",
         "Spain",
         "Female",
         "43",
         "2",
         "125510.82",
         "1",
         "1",
         "1",
         "79084.1",
         "0"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"data/Churn_Modelling.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check possible values in Geogrpahy and Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "Male      5457\n",
       "Female    4543\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geography\n",
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Geography\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    7963\n",
       "1    2037\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Exited\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove RowNumber, CustomerId and Surname columns from features.  Exited is the target/dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (10000, 10), y shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=[\"RowNumber\", \"CustomerId\", \"Surname\", \"Exited\"])\n",
    "y = df[\"Exited\"]\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate categorical and numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns: ['Geography', 'Gender']\n",
      "Numerical Columns: ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n"
     ]
    }
   ],
   "source": [
    "categ_columns = [\"Geography\", \"Gender\"]\n",
    "num_columns = X.drop(columns=categ_columns).columns.tolist()\n",
    "print(f\"Categorical Columns: {categ_columns}\")\n",
    "print(f\"Numerical Columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Columntransformer with different transformations for numerical and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ct = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), num_columns),\n",
    "    ('cat', OneHotEncoder(drop=\"first\"), categ_columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60% training, 20% validation, 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6000, 10), X_val shape: (2000, 10), X_test shape: (2000, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=0.6, random_state=0)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0)\n",
    "print(f\"X_train shape: {X_train.shape}, X_val shape: {X_val.shape}, X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use column transformer, only fit to Train data and use the training fit to scale all datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6000, 11), X_val shape: (2000, 11), X_test shape: (2000, 11)\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled = ct.fit_transform(X_train)\n",
    "X_val_scaled = ct.transform(X_val)\n",
    "X_test_scaled = ct.transform(X_test)\n",
    "print(f\"X_train shape: {X_train_scaled.shape}, X_val shape: {X_val_scaled.shape}, X_test shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    \"\"\"\n",
    "    Build a ANN with hidden layers and sigmoid output layer\n",
    "\n",
    "    Inputs: hp - Hyperparameters\n",
    "\n",
    "    Outputs: model - ANN model\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    # Hidden Layer 0\n",
    "    model.add(Dense(units=hp.Int('units_0', min_value=32, max_value=128, step=32), \n",
    "                    activation=hp.Choice('activation', values=['relu','tanh','sigmoid']), \n",
    "                    input_shape=(X_train_scaled.shape[1],)))\n",
    "    \n",
    "    # Hidden Layer 1\n",
    "    model.add(Dense(units=hp.Int('units_1', min_value=32, max_value=128, step=32), \n",
    "                    activation=hp.Choice('activation', values=['relu','tanh','sigmoid'])))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Compile \n",
    "    model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate performance of an ANN model\n",
    "\n",
    "    Inputs: model - trained ANN model\n",
    "            X_test - test features\n",
    "            y_test - test labels\n",
    "            \n",
    "    Outputs: loss - loss of the model\n",
    "    \"\"\"\n",
    "    test_loss = model.evaluate(X_test, y_test, verbose=0)[0]\n",
    "\n",
    "    return test_loss\n",
    "\n",
    "# Number of trials and epochs\n",
    "max_trials = 10\n",
    "max_epochs = 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfrom Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40 Complete [00h 00m 02s]\n",
      "val_loss: 0.35002487897872925\n",
      "\n",
      "Best val_loss So Far: 0.3415829539299011\n",
      "Total elapsed time: 00h 01m 33s\n",
      "Random Search Time: 93.3198390007019 seconds\n",
      "Random Search Test Loss: 0.3551115095615387\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import GridSearch\n",
    "\n",
    "grid_tuner = GridSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=40,\n",
    "    executions_per_trial=1,\n",
    "    directory='hyperparam_tuning',\n",
    "    project_name='grid_search',\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "time_start = time.time()\n",
    "grid_tuner.search(X_train_scaled, y_train, epochs=max_epochs, validation_data=(X_val_scaled, y_val))\n",
    "time_end = time.time()\n",
    "grid_search_time = time_end - time_start\n",
    "print(f\"Random Search Time: {grid_search_time} seconds\")\n",
    "\n",
    "\n",
    "grid_search_best_model = grid_tuner.get_best_models(num_models=1)[0]\n",
    "grid_search_test_loss = evaluate_model(grid_search_best_model, X_test_scaled, y_test)\n",
    "grid_search_best_hyperparams = grid_tuner.get_best_hyperparameters(num_trials=1)[0].values\n",
    "print(f\"Random Search Test Loss: {grid_search_test_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 02s]\n",
      "val_loss: 0.3366333544254303\n",
      "\n",
      "Best val_loss So Far: 0.3366333544254303\n",
      "Total elapsed time: 00h 00m 20s\n",
      "Random Search Time: 20.38971972465515 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MyGithub\\ML_TensorFlow_Keras_Experiments\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search Test Loss: 0.35044774413108826\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "\n",
    "random_tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=max_trials,\n",
    "    directory='hyperparam_tuning',\n",
    "    project_name='random_search',\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "time_start = time.time()\n",
    "random_tuner.search(X_train_scaled, y_train, epochs=max_epochs, validation_data=(X_val_scaled, y_val))\n",
    "time_end = time.time()\n",
    "random_search_time = time_end - time_start\n",
    "print(f\"Random Search Time: {random_search_time} seconds\")\n",
    "\n",
    "\n",
    "random_search_best_model = random_tuner.get_best_models(num_models=1)[0]\n",
    "random_search_test_loss = evaluate_model(random_search_best_model, X_test_scaled, y_test)\n",
    "random_search_best_hyperparams = random_tuner.get_best_hyperparameters(num_trials=1)[0].values\n",
    "print(f\"Random Search Test Loss: {random_search_test_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 02s]\n",
      "val_loss: 0.35231727361679077\n",
      "\n",
      "Best val_loss So Far: 0.3447740077972412\n",
      "Total elapsed time: 00h 00m 20s\n",
      "Bayesian Search Time: 20.085747480392456 seconds\n",
      "Bayesian Search Test Loss: 0.35379666090011597\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import BayesianOptimization\n",
    "\n",
    "bayesian_tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=max_trials,\n",
    "    directory='hyperparam_tuning',\n",
    "    project_name='bayesian_search',\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "time_start = time.time()\n",
    "bayesian_tuner.search(X_train_scaled, y_train, epochs=max_epochs, validation_data=(X_val_scaled, y_val))\n",
    "time_end = time.time()\n",
    "bayesian_search_time = time_end - time_start\n",
    "print(f\"Bayesian Search Time: {bayesian_search_time} seconds\")\n",
    "\n",
    "bayesian_search_best_model = bayesian_tuner.get_best_models(num_models=1)[0]\n",
    "bayesian_search_test_loss = evaluate_model(bayesian_search_best_model, X_test_scaled, y_test)\n",
    "bayesian_search_best_hyperparams = bayesian_tuner.get_best_hyperparameters(num_trials=1)[0].values\n",
    "print(f\"Bayesian Search Test Loss: {bayesian_search_test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperband Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 04s]\n",
      "val_loss: 0.34407493472099304\n",
      "\n",
      "Best val_loss So Far: 0.3385373651981354\n",
      "Total elapsed time: 00h 00m 32s\n",
      "Bayesian Search Time: 31.596726655960083 seconds\n",
      "Bayesian Search Test Loss: 0.358199805021286\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import Hyperband\n",
    "\n",
    "hyperband_tuner = Hyperband(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    #max_epochs=max_epochs,\n",
    "    max_epochs=8,\n",
    "    directory='hyperparam_tuning',\n",
    "    project_name='hyperband_search',\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "time_start = time.time()\n",
    "hyperband_tuner.search(X_train_scaled, y_train, validation_data=(X_val_scaled, y_val))\n",
    "time_end = time.time()\n",
    "hyperband_search_time = time_end - time_start\n",
    "print(f\"Bayesian Search Time: {hyperband_search_time} seconds\")\n",
    "\n",
    "hyperband_search_best_model = hyperband_tuner.get_best_models(num_models=1)[0]\n",
    "hyperband_search_test_loss = evaluate_model(hyperband_search_best_model, X_test_scaled, y_test)\n",
    "hyperband_search_best_hyperparams = hyperband_tuner.get_best_hyperparameters(num_trials=1)[0].values\n",
    "print(f\"Bayesian Search Test Loss: {hyperband_search_test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Method  Test Loss  Time (seconds)  \\\n",
      "0            Grid Search   0.355112       93.319839   \n",
      "1          Random Search   0.350448       20.389720   \n",
      "2  Bayesian Optimization   0.353797       20.085747   \n",
      "3              Hyperband   0.358200       31.596727   \n",
      "\n",
      "                                                                                                                                                                         Best Hyperparameters  \n",
      "0                                                                                                                {'units_0': 32, 'activation': 'tanh', 'units_1': 128, 'learning_rate': 0.01}  \n",
      "1                                                                                                                 {'units_0': 64, 'activation': 'relu', 'units_1': 32, 'learning_rate': 0.01}  \n",
      "2                                                                                                                 {'units_0': 64, 'activation': 'tanh', 'units_1': 64, 'learning_rate': 0.01}  \n",
      "3  {'units_0': 32, 'activation': 'relu', 'units_1': 128, 'learning_rate': 0.001, 'tuner/epochs': 8, 'tuner/initial_epoch': 3, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0004'}  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Collect results\n",
    "results = {\n",
    "    \"Method\": [\"Grid Search\", \"Random Search\", \"Bayesian Optimization\", \"Hyperband\"],\n",
    "    \"Test Loss\": [grid_search_test_loss, \n",
    "                  random_search_test_loss, \n",
    "                  bayesian_search_test_loss, \n",
    "                  hyperband_search_test_loss],\n",
    "    \"Time (seconds)\": [grid_search_time, random_search_time, bayesian_search_time, hyperband_search_time],\n",
    "    \"Best Hyperparameters\": [\n",
    "        grid_search_best_hyperparams,\n",
    "        random_search_best_hyperparams,\n",
    "        bayesian_search_best_hyperparams,\n",
    "        hyperband_search_best_hyperparams\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Display results in DataFrame \n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in hyperparam_tuning\\grid_search\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 21 summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "activation: tanh\n",
      "units_1: 128\n",
      "learning_rate: 0.01\n",
      "Score: 0.3415829539299011\n",
      "\n",
      "Trial 36 summary\n",
      "Hyperparameters:\n",
      "units_0: 64\n",
      "activation: relu\n",
      "units_1: 32\n",
      "learning_rate: 0.01\n",
      "Score: 0.3415847718715668\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "activation: relu\n",
      "units_1: 96\n",
      "learning_rate: 0.01\n",
      "Score: 0.3422064781188965\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "activation: relu\n",
      "units_1: 32\n",
      "learning_rate: 0.01\n",
      "Score: 0.34253597259521484\n",
      "\n",
      "Trial 12 summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "activation: tanh\n",
      "units_1: 32\n",
      "learning_rate: 0.01\n",
      "Score: 0.3452119529247284\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "activation: relu\n",
      "units_1: 64\n",
      "learning_rate: 0.01\n",
      "Score: 0.3461155295372009\n",
      "\n",
      "Trial 15 summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "activation: tanh\n",
      "units_1: 64\n",
      "learning_rate: 0.01\n",
      "Score: 0.34647300839424133\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "activation: relu\n",
      "units_1: 128\n",
      "learning_rate: 0.01\n",
      "Score: 0.34661784768104553\n",
      "\n",
      "Trial 39 summary\n",
      "Hyperparameters:\n",
      "units_0: 64\n",
      "activation: relu\n",
      "units_1: 64\n",
      "learning_rate: 0.01\n",
      "Score: 0.35002487897872925\n",
      "\n",
      "Trial 27 summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "activation: sigmoid\n",
      "units_1: 64\n",
      "learning_rate: 0.01\n",
      "Score: 0.35515955090522766\n"
     ]
    }
   ],
   "source": [
    "grid_tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in hyperparam_tuning\\random_search\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "units_0: 64\n",
      "activation: relu\n",
      "units_1: 32\n",
      "learning_rate: 0.01\n",
      "Score: 0.3366333544254303\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "units_0: 64\n",
      "activation: tanh\n",
      "units_1: 96\n",
      "learning_rate: 0.01\n",
      "Score: 0.35299354791641235\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "units_0: 64\n",
      "activation: relu\n",
      "units_1: 32\n",
      "learning_rate: 0.001\n",
      "Score: 0.3533097207546234\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "units_0: 64\n",
      "activation: sigmoid\n",
      "units_1: 96\n",
      "learning_rate: 0.01\n",
      "Score: 0.3937161862850189\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "units_0: 128\n",
      "activation: sigmoid\n",
      "units_1: 96\n",
      "learning_rate: 0.001\n",
      "Score: 0.4241953492164612\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "units_0: 96\n",
      "activation: sigmoid\n",
      "units_1: 96\n",
      "learning_rate: 0.001\n",
      "Score: 0.424972802400589\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "units_0: 96\n",
      "activation: tanh\n",
      "units_1: 96\n",
      "learning_rate: 0.0001\n",
      "Score: 0.4312063455581665\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "units_0: 64\n",
      "activation: sigmoid\n",
      "units_1: 96\n",
      "learning_rate: 0.001\n",
      "Score: 0.4318635165691376\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "units_0: 96\n",
      "activation: relu\n",
      "units_1: 32\n",
      "learning_rate: 0.0001\n",
      "Score: 0.45338454842567444\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "activation: sigmoid\n",
      "units_1: 96\n",
      "learning_rate: 0.0001\n",
      "Score: 0.4974770247936249\n"
     ]
    }
   ],
   "source": [
    "random_tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in hyperparam_tuning\\bayesian_search\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "units_0: 64\n",
      "activation: tanh\n",
      "units_1: 64\n",
      "learning_rate: 0.01\n",
      "Score: 0.3447740077972412\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "units_0: 64\n",
      "activation: sigmoid\n",
      "units_1: 64\n",
      "learning_rate: 0.01\n",
      "Score: 0.35119953751564026\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "units_0: 96\n",
      "activation: tanh\n",
      "units_1: 32\n",
      "learning_rate: 0.001\n",
      "Score: 0.35231727361679077\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "units_0: 128\n",
      "activation: sigmoid\n",
      "units_1: 128\n",
      "learning_rate: 0.01\n",
      "Score: 0.35321956872940063\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "units_0: 96\n",
      "activation: tanh\n",
      "units_1: 128\n",
      "learning_rate: 0.001\n",
      "Score: 0.35659506916999817\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "activation: sigmoid\n",
      "units_1: 32\n",
      "learning_rate: 0.01\n",
      "Score: 0.36340999603271484\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "activation: sigmoid\n",
      "units_1: 64\n",
      "learning_rate: 0.001\n",
      "Score: 0.4252559244632721\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "units_0: 96\n",
      "activation: sigmoid\n",
      "units_1: 64\n",
      "learning_rate: 0.001\n",
      "Score: 0.4287329316139221\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "units_0: 96\n",
      "activation: relu\n",
      "units_1: 128\n",
      "learning_rate: 0.0001\n",
      "Score: 0.4322284460067749\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "units_0: 128\n",
      "activation: relu\n",
      "units_1: 32\n",
      "learning_rate: 0.0001\n",
      "Score: 0.43410587310791016\n"
     ]
    }
   ],
   "source": [
    "bayesian_tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in hyperparam_tuning\\hyperband_search\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 0006 summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "activation: relu\n",
      "units_1: 128\n",
      "learning_rate: 0.001\n",
      "tuner/epochs: 8\n",
      "tuner/initial_epoch: 3\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0004\n",
      "Score: 0.3385373651981354\n",
      "\n",
      "Trial 0007 summary\n",
      "Hyperparameters:\n",
      "units_0: 96\n",
      "activation: tanh\n",
      "units_1: 96\n",
      "learning_rate: 0.01\n",
      "tuner/epochs: 8\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.3419856131076813\n",
      "\n",
      "Trial 0009 summary\n",
      "Hyperparameters:\n",
      "units_0: 64\n",
      "activation: relu\n",
      "units_1: 96\n",
      "learning_rate: 0.01\n",
      "tuner/epochs: 8\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.34407493472099304\n",
      "\n",
      "Trial 0005 summary\n",
      "Hyperparameters:\n",
      "units_0: 128\n",
      "activation: tanh\n",
      "units_1: 64\n",
      "learning_rate: 0.01\n",
      "tuner/epochs: 8\n",
      "tuner/initial_epoch: 3\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0000\n",
      "Score: 0.3444349765777588\n",
      "\n",
      "Trial 0000 summary\n",
      "Hyperparameters:\n",
      "units_0: 128\n",
      "activation: tanh\n",
      "units_1: 64\n",
      "learning_rate: 0.01\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.3488605320453644\n",
      "\n",
      "Trial 0004 summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "activation: relu\n",
      "units_1: 128\n",
      "learning_rate: 0.001\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.3534095585346222\n",
      "\n",
      "Trial 0008 summary\n",
      "Hyperparameters:\n",
      "units_0: 32\n",
      "activation: sigmoid\n",
      "units_1: 64\n",
      "learning_rate: 0.001\n",
      "tuner/epochs: 8\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.41599979996681213\n",
      "\n",
      "Trial 0002 summary\n",
      "Hyperparameters:\n",
      "units_0: 128\n",
      "activation: tanh\n",
      "units_1: 128\n",
      "learning_rate: 0.0001\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.43043243885040283\n",
      "\n",
      "Trial 0001 summary\n",
      "Hyperparameters:\n",
      "units_0: 96\n",
      "activation: sigmoid\n",
      "units_1: 64\n",
      "learning_rate: 0.0001\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.4905456304550171\n",
      "\n",
      "Trial 0003 summary\n",
      "Hyperparameters:\n",
      "units_0: 128\n",
      "activation: sigmoid\n",
      "units_1: 32\n",
      "learning_rate: 0.0001\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.49802061915397644\n"
     ]
    }
   ],
   "source": [
    "hyperband_tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
